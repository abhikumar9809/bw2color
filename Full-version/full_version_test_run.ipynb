{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'keras' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get images\n",
    "X = []\n",
    "path=\"/floyd/input/data/testdata/Train/\"\n",
    "for filename in os.listdir(path):\n",
    "    X.append(img_to_array(load_img(path+filename)))\n",
    "X = np.array(X, dtype=float)\n",
    "Xtrain = 1.0/255*X\n",
    "\n",
    "\n",
    "#Load weights\n",
    "inception = InceptionResNetV2(weights=None, include_top=True)\n",
    "inception.load_weights('/floyd/input/data/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "inception.graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_input = Input(shape=(1000,))\n",
    "\n",
    "#Encoder\n",
    "encoder_input = Input(shape=(256, 256, 1,))\n",
    "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "\n",
    "#Fusion\n",
    "fusion_output = RepeatVector(32 * 32)(embed_input) \n",
    "fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
    "fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
    "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n",
    "\n",
    "#Decoder\n",
    "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 55s 55s/step - loss: 0.0067\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.3866\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0137\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0065\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0116\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0061\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0057\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0075\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0062\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0061\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0065\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0062\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0063\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0057\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0061\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0060\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0057\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0057\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0058\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0057\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0055\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0061\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0056\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0057\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0057\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0060\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0056\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0059\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0058\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0057\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0056\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0053\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0055\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0058\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0057\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0051\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0052\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0055\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0055\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0055\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0055\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0049\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0064\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0058\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0058\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0057\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0056\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0061\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0054\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0055\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0058\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0062\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0055\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0056\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0057\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0057\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0053\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0056\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0058\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0056\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0054\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0055\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0056\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0057\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0056\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0057\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0059\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0055\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0057\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0054\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0056\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0059\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0055\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0057\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0053\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0056\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0056\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0053\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0056\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0054\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0058\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0055\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0055\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0058\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0056\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0057\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0055\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0056\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0055\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0055\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0054\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0054\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0053\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0050\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0056\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0054\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0057\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.0057\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0053\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.0053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad4fe3e438>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create embedding\n",
    "def create_inception_embedding(grayscaled_rgb):\n",
    "    grayscaled_rgb_resized = []\n",
    "    for i in grayscaled_rgb:\n",
    "        i = resize(i, (299, 299, 3), mode='constant')\n",
    "        grayscaled_rgb_resized.append(i)\n",
    "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
    "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
    "    with inception.graph.as_default():\n",
    "        embed = inception.predict(grayscaled_rgb_resized)\n",
    "    return embed\n",
    "\n",
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "#Generate training data\n",
    "batch_size = 10\n",
    "\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
    "        embed = create_inception_embedding(grayscaled_rgb)\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield ([X_batch, create_inception_embedding(grayscaled_rgb)], Y_batch)\n",
    "\n",
    "\n",
    "#Train model      \n",
    "tensorboard = TensorBoard(log_dir=\"/output\")\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit_generator(image_a_b_gen(batch_size), callbacks=[tensorboard], epochs=100, steps_per_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"color_tensorflow_test_run.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/usr/local/lib/python3.6/site-packages/skimage/util/dtype.py:130: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "color_me = []\n",
    "path=\"/floyd/input/data/testdata/Validate/\"\n",
    "for filename in os.listdir(path):\n",
    "    color_me.append(img_to_array(load_img(path+filename)))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = 1.0/255*color_me\n",
    "color_me = gray2rgb(rgb2gray(color_me))\n",
    "color_me_embed = create_inception_embedding(color_me)\n",
    "color_me = rgb2lab(color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "\n",
    "# Test model\n",
    "output = model.predict([color_me, color_me_embed])\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = color_me[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    imsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
